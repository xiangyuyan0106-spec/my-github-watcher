name: '[Monitor] BYOVD & EDR Evasion Projects & Updates'
on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  discover:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Setup GitHub CLI and jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          sudo apt update
          sudo apt install gh -y

      - name: Authenticate GitHub CLI
        run: echo "${{ secrets.GH_PAT }}" | gh auth login --with-token

      - name: Upload debug files
        if: always() # å³ä½¿å¤±è´¥ä¹Ÿè¿è¡Œ
        uses: actions/upload-artifact@v4
        with:
          name: debug-files
          path: |
            api_response.json
            latest_results.json
          retention-days: 1
          
      - name: Fetch latest project updates
        run: |
          QUERY="%22BYOVD%22%20AND%20(kill%20OR%20antiav%20OR%20antiedr)%20in:name,description,readme"
          API_URL="https://api.github.com/search/repositories?q=$QUERY&sort=updated&order=desc&per_page=30"
          echo "è°ƒç”¨API: $API_URL"
          
          # è·å–å®Œæ•´çš„APIå“åº”
          gh api "$API_URL" > api_response.json
          sed -r 's/\x1B\[[0-9;]*[mK]//g' api_response.json > clean.json
          mv clean.json api_response.json
          
          # æŸ¥çœ‹æ–‡ä»¶å‰å‡ è¡Œå†…å®¹ï¼Œå¸®åŠ©è°ƒè¯•
          echo "=== APIå“åº”æ–‡ä»¶å‰200ä¸ªå­—ç¬¦ ==="
          head -c 300 api_response.json
          echo -e "\n\n=== jsonstart ==="
          head -n1 api_response.json | cat -A
          echo -e "\n\n=== æ–‡ä»¶ä¿¡æ¯ ==="
          ls -la api_response.json
          echo "æ–‡ä»¶å¤§å°: $(wc -c < api_response.json) å­—èŠ‚"
          
          # å°è¯•è§£æJSONçœ‹æ˜¯å¦æœ‰æ•ˆ
          if jq . api_response.json > /dev/null 2>&1; then
            echo "âœ… JSONæ ¼å¼æœ‰æ•ˆ"
            echo "æ‰¾åˆ° $(jq '.items | length' api_response.json) ä¸ªé¡¹ç›®"
          else
            echo "âŒ JSONæ ¼å¼æ— æ•ˆï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼š"
            jq . api_response.json 2>&1 | head -20
          fi
          
          # ä½¿ç”¨jqä»å“åº”ä¸­æå–itemsæ•°ç»„å¹¶æ ¼å¼åŒ–ä¸ºæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
          jq -c '.items[] | {full_name, html_url, description, stargazers_count, updated_at, pushed_at, created_at, topics }' api_response.json > latest_results.json
          
          # æå–é¡¹ç›®URL
          jq -r '.html_url' latest_results.json > current_urls.txt
        env:
          GH_FORCE_TTY: 0

      - name: Retrieve previous state
        run: |
          if [ -f previous_results.json ]; then
            cp previous_results.json previous_results_backup.json
            jq -r '.html_url' previous_results.json > previous_urls.txt
          else
            touch previous_urls.txt
            echo "[]" > previous_results_backup.json
          fi

      - name: Identify new and updated projects
        id: check_changes
        run: |
          grep -Fxv -f previous_urls.txt current_urls.txt > new_items.txt || true
          NEW_COUNT=$(wc -l < new_items.txt | tr -d ' ')
          echo "å‘ç° $NEW_COUNT ä¸ªæ–°é¡¹ç›®"
          cat new_items.txt

          # åˆ›å»ºPythonè„šæœ¬æ¥æ£€æµ‹æ›´æ–°
          # cat > detect_updates.py << 'EOF'
          echo "import json" > detect_updates.py
          echo "from datetime import datetime, timedelta" >> detect_updates.py
          echo "import os" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "# åŠ è½½å½“å‰ç»“æœ" >> detect_updates.py
          echo "current_items = []" >> detect_updates.py
          echo "if os.path.exists('latest_results.json'):" >> detect_updates.py
          echo "    with open('latest_results.json', 'r') as f:" >> detect_updates.py
          echo "        for line in f:" >> detect_updates.py
          echo "            if line.strip():" >> detect_updates.py
          echo "                try:" >> detect_updates.py
          echo "                    current_items.append(json.loads(line))" >> detect_updates.py
          echo "                except json.JSONDecodeError:" >> detect_updates.py
          echo "                    pass" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "# åŠ è½½ä¹‹å‰çš„ç»“æœ" >> detect_updates.py
          echo "previous_items = []" >> detect_updates.py
          echo "if os.path.exists('previous_results_backup.json'):" >> detect_updates.py
          echo "    with open('previous_results_backup.json', 'r') as f:" >> detect_updates.py
          echo "        for line in f:" >> detect_updates.py
          echo "            if line.strip():" >> detect_updates.py
          echo "                try:" >> detect_updates.py
          echo "                    previous_items.append(json.loads(line))" >> detect_updates.py
          echo "                except json.JSONDecodeError:" >> detect_updates.py
          echo "                    pass" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "# åˆ›å»ºæ˜ å°„ä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾" >> detect_updates.py
          echo "previous_map = {item['html_url']: item for item in previous_items if 'html_url' in item}" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "updated_count = 0" >> detect_updates.py
          echo "updated_urls = []" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "for current in current_items:" >> detect_updates.py
          echo "    url = current.get('html_url')" >> detect_updates.py
          echo "    if not url or url not in previous_map:" >> detect_updates.py
          echo "        continue" >> detect_updates.py
          echo "        " >> detect_updates.py
          echo "    previous = previous_map[url]" >> detect_updates.py
          echo "    " >> detect_updates.py
          echo "    try:" >> detect_updates.py
          echo "        # è§£ææ—¶é—´å­—ç¬¦ä¸²" >> detect_updates.py
          echo "        current_updated = datetime.fromisoformat(current['updated_at'].replace('Z', '+00:00'))" >> detect_updates.py
          echo "        previous_updated = datetime.fromisoformat(previous['updated_at'].replace('Z', '+00:00'))" >> detect_updates.py
          echo "        " >> detect_updates.py
          echo "        # æ£€æŸ¥æ˜¯å¦åœ¨æœ€è¿‘ä¸€æ¬¡æ£€æŸ¥ä¹‹åæœ‰æ›´æ–°" >> detect_updates.py
          echo "        if current_updated > previous_updated + timedelta(hours=1):" >> detect_updates.py
          echo "            # æ£€æŸ¥å…¶ä»–é‡è¦å˜åŒ–" >> detect_updates.py
          echo "            star_increase = current.get('stargazers_count', 0) - previous.get('stargazers_count', 0)" >> detect_updates.py
          echo "            current_topics = set(current.get('topics', []))" >> detect_updates.py
          echo "            previous_topics = set(previous.get('topics', []))" >> detect_updates.py
          echo "            new_topics = current_topics - previous_topics" >> detect_updates.py
          echo "            " >> detect_updates.py
          echo "            # å¦‚æœæœ‰æ˜¾è‘—æ›´æ–°ï¼Œåˆ™æ ‡è®°" >> detect_updates.py
          echo "            if (current_updated - previous_updated).days < 7 or star_increase > 2 or new_topics:" >> detect_updates.py
          echo "                updated_count += 1" >> detect_updates.py
          echo "                updated_urls.append(url)" >> detect_updates.py
          echo "                print(f'æ£€æµ‹åˆ°æ›´æ–°: {url}')" >> detect_updates.py
          echo "                " >> detect_updates.py
          echo "    except (KeyError, ValueError, TypeError) as e:" >> detect_updates.py
          echo "        print(f'å¤„ç†é¡¹ç›® {url} æ—¶å‡ºé”™: {e}')" >> detect_updates.py
          echo "        continue" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "# ä¿å­˜æ›´æ–°åˆ—è¡¨" >> detect_updates.py
          echo "with open('updated_items.txt', 'w') as f:" >> detect_updates.py
          echo "    for url in updated_urls:" >> detect_updates.py
          echo "        f.write(f'{url}\\n')" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "print(f'å‘ç° {updated_count} ä¸ªé¡¹ç›®æœ‰æ›´æ–°')" >> detect_updates.py
          
          # æ‰§è¡ŒPythonè„šæœ¬
          python3 detect_updates.py
          UPDATED_COUNT=$(wc -l < updated_items.txt | tr -d ' ')
          echo "CHANGE_COUNT=$((NEW_COUNT + UPDATED_COUNT))" >> $GITHUB_ENV
          echo "NEW_COUNT=$NEW_COUNT" >> $GITHUB_ENV
          echo "UPDATED_COUNT=$UPDATED_COUNT" >> $GITHUB_ENV
          
          if [ "$NEW_COUNT" -gt 0 ] || [ "$UPDATED_COUNT" -gt 0 ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi
      - name: Generate RSS feed for changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          CURRENT_DATE=$(date -u +"%a, %d %b %Y %H:%M:%S GMT")
          RSS_ITEM_FILE="rss_items.xml"
          # å…ˆæ¸…ç©ºæ—§å†…å®¹
          echo "" > $RSS_ITEM_FILE
      
          # ç”Ÿæˆæ–°é¡¹ç›®çš„ RSS é¡¹ç›®
          if [ -s new_items.txt ]; then
            echo "=== ç”Ÿæˆæ–°é¡¹ç›® RSS é¡¹ç›® ==="
            while read -r url; do
              jq -r --arg url "$url" --arg date "$CURRENT_DATE" '
                .[] | select(.html_url == $url) |
                "  <item>\n    <title>ğŸš€ æ–°é¡¹ç›®: \(.full_name)</title>\n    <link>\(.html_url)</link>\n    <description>æ–°å‘ç°çš„BYOVD/EDRå¯¹æŠ—é¡¹ç›®ã€‚æè¿°: \(.description // \"No description\" | @html)</description>\n    <pubDate>\($date)</pubDate>\n    <guid isPermaLink=\"true\">\(.html_url)?new=1</guid>\n  </item>"
              ' latest_results.json >> $RSS_ITEM_FILE
            done < new_items.txt
          fi
      
          # ç”Ÿæˆæ›´æ–°é¡¹ç›®çš„ RSS é¡¹ç›®
          if [ -s updated_items.txt ]; then
            echo "=== ç”Ÿæˆæ›´æ–°é¡¹ç›® RSS é¡¹ç›® ==="
            while read -r url; do
              jq -r --arg url "$url" --arg date "$CURRENT_DATE" '
                .[] | select(.html_url == $url) |
                "  <item>\n    <title>ğŸ“¢ æ›´æ–°: \(.full_name)</title>\n    <link>\(.html_url)</link>\n    <description>é¡¹ç›®æœ‰é‡è¦æ›´æ–°ï¼Œå¯èƒ½å‘å¸ƒäº†æ–°ç‰ˆæœ¬æˆ–æ·»åŠ äº†æ–°åŠŸèƒ½ã€‚æè¿°: \(.description // \"No description\" | @html)</description>\n    <pubDate>\($date)</pubDate>\n    <guid isPermaLink=\"true\">\(.html_url)?updated=\(now|floor)</guid>\n  </item>"
              ' latest_results.json >> $RSS_ITEM_FILE
            done < updated_items.txt
          fi
      
          echo "ç”Ÿæˆ RSS é¡¹ç›®å®Œæˆï¼Œæ–‡ä»¶: $RSS_ITEM_FILE"



      - name: Update RSS feed and persist state
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          # åˆ›å»º Python è„šæœ¬
          echo "import xml.etree.ElementTree as ET" > update_rss.py
          echo "from xml.dom import minidom" >> update_rss.py
          echo "import datetime" >> update_rss.py
          echo "import os" >> update_rss.py
          echo "" >> update_rss.py
          echo "rss_file = 'feed.xml'" >> update_rss.py
          echo "rss_item_file = 'rss_items.xml'" >> update_rss.py
          echo "" >> update_rss.py
          echo "# åˆ›å»ºæˆ–è§£æ feed.xml" >> update_rss.py
          echo "if os.path.exists(rss_file):" >> update_rss.py
          echo "    try:" >> update_rss.py
          echo "        tree = ET.parse(rss_file)" >> update_rss.py
          echo "        root = tree.getroot()" >> update_rss.py
          echo "        channel = root.find('channel')" >> update_rss.py
          echo "        if channel is None:" >> update_rss.py
          echo "            channel = ET.SubElement(root, 'channel')" >> update_rss.py
          echo "    except:" >> update_rss.py
          echo "        root = ET.Element('rss', version='2.0')" >> update_rss.py
          echo "        channel = ET.SubElement(root, 'channel')" >> update_rss.py
          echo "else:" >> update_rss.py
          echo "    root = ET.Element('rss', version='2.0')" >> update_rss.py
          echo "    channel = ET.SubElement(root, 'channel')" >> update_rss.py
          echo "    title = ET.SubElement(channel, 'title')" >> update_rss.py
          echo "    title.text = 'GitHub Monitor: BYOVD & EDR Evasion'" >> update_rss.py
          echo "    link = ET.SubElement(channel, 'link')" >> update_rss.py
          echo "    link.text = f'https://github.com/${{ github.repository }}'" >> update_rss.py
          echo "    description = ET.SubElement(channel, 'description')" >> update_rss.py
          echo "    description.text = 'ç›‘æ§BYOVDåŠEDRå¯¹æŠ—é¡¹ç›®çš„æ›´æ–°å’Œæ–°å‡ºç°'" >> update_rss.py
          echo "    language = ET.SubElement(channel, 'language')" >> update_rss.py
          echo "    language.text = 'en-us'" >> update_rss.py
          echo "" >> update_rss.py
          echo "# è¿½åŠ æ–°çš„ <item>" >> update_rss.py
          echo "if os.path.exists(rss_item_file):" >> update_rss.py
          echo "    try:" >> update_rss.py
          echo "        item_tree = ET.parse(rss_item_file)" >> update_rss.py
          echo "        for item in item_tree.findall('item'):" >> update_rss.py
          echo "            channel.append(item)" >> update_rss.py
          echo "    except Exception as e:" >> update_rss.py
          echo "        print(f'è§£æRSSé¡¹ç›®æ—¶å‡ºé”™: {e}')" >> update_rss.py
          echo "" >> update_rss.py
          echo "# æ›´æ–° lastBuildDate" >> update_rss.py
          echo "last_build_date = channel.find('lastBuildDate')" >> update_rss.py
          echo "if last_build_date is None:" >> update_rss.py
          echo "    last_build_date = ET.SubElement(channel, 'lastBuildDate')" >> update_rss.py
          echo "last_build_date.text = datetime.datetime.now(datetime.timezone.utc).strftime('%a, %d %b %Y %H:%M:%S GMT')" >> update_rss.py
          echo "" >> update_rss.py
          echo "# ä¿å­˜ feed.xml" >> update_rss.py
          echo "rough_string = ET.tostring(root, encoding='unicode')" >> update_rss.py
          echo "parsed = minidom.parseString(rough_string)" >> update_rss.py
          echo "with open(rss_file, 'w', encoding='utf-8') as f:" >> update_rss.py
          echo "    f.write(parsed.toprettyxml(indent='  '))" >> update_rss.py
          echo "" >> update_rss.py
          echo "print('âœ… RSS feedæ›´æ–°å®Œæˆ')" >> update_rss.py

          # æ‰§è¡Œ Python è„šæœ¬
          python3 update_rss.py

          # ä¿å­˜å½“å‰çŠ¶æ€ç”¨äºä¸‹æ¬¡å¯¹æ¯”
          cp latest_results.json previous_results.json
          cp current_urls.txt previous_urls.txt

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add feed.xml previous_results.json previous_urls.txt
          git commit -m "CI: Found ${{ env.CHANGE_COUNT }} changes ($NEW_COUNT new, $UPDATED_COUNT updated)" || true
          git push || true

      - name: No changes notification
        if: steps.check_changes.outputs.has_changes == 'false'
        run: |
          date +"%Y-%m-%d %H:%M:%S - No changes detected" >> monitor.log
          git add monitor.log
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git commit -m "CI: Monitoring completed, no changes" || exit 0
          git push || exit 0
