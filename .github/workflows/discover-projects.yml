name: '[Monitor] BYOVD & EDR Evasion Projects & Updates'
on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  discover:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}
          fetch-depth: 0

      - name: Setup environment
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl python3 python3-pip
          pip3 install beautifulsoup4
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          sudo apt update
          sudo apt install gh -y

      - name: Authenticate GitHub CLI
        run: echo "${{ secrets.GH_PAT }}" | gh auth login --with-token

      - name: Fetch GitHub projects
        run: |
          QUERY="%22BYOVD%22%20AND%20(kill%20OR%20antiav%20OR%20antiedr)%20in:name,description,readme"
          API_URL="https://api.github.com/search/repositories?q=$QUERY&sort=updated&order=desc&per_page=30"
          echo "è°ƒç”¨API: $API_URL"
          
          # è·å–APIå“åº”
          gh api "$API_URL" > api_response.json
          sed -r 's/\x1B\[[0-9;]*[mK]//g' api_response.json > clean.json
          mv clean.json api_response.json
          # æ£€æŸ¥JSONæœ‰æ•ˆæ€§
          if jq . api_response.json > /dev/null 2>&1; then
            echo "âœ… JSONæ ¼å¼æœ‰æ•ˆ"
            TOTAL_COUNT=$(jq '.total_count' api_response.json)
            echo "æ‰¾åˆ° $TOTAL_COUNT ä¸ªé¡¹ç›®ï¼Œè·å–äº† $(jq '.items | length' api_response.json) ä¸ªé¡¹ç›®"
          else
            echo "âŒ JSONæ ¼å¼æ— æ•ˆ"
            exit 1
          fi
          
          # æå–é¡¹ç›®ä¿¡æ¯
          jq -c '.items[] | {full_name, html_url, description, stargazers_count, updated_at, pushed_at, created_at, topics }' api_response.json > latest_results.json
          jq -r '.html_url' latest_results.json > current_urls.txt

      - name: Retrieve previous state
        run: |
          if [ -f previous_results.json ]; then
            cp previous_results.json previous_results_backup.json
            jq -r '.html_url' previous_results_backup.json 2>/dev/null > previous_urls.txt || echo "[]" > previous_results_backup.json
          else
            echo "[]" > previous_results_backup.json
            touch previous_urls.txt
          fi

      - name: Identify changes
        id: check_changes
        run: |
          # æ£€æµ‹æ–°é¡¹ç›®
          grep -Fxv -f previous_urls.txt current_urls.txt > new_items.txt || true
          NEW_COUNT=$(wc -l < new_items.txt | tr -d ' ')
          echo "å‘ç° $NEW_COUNT ä¸ªæ–°é¡¹ç›®"

          # åˆ›å»ºæ£€æµ‹æ›´æ–°çš„Pythonè„šæœ¬
          echo "import json" > detect_updates.py
          echo "from datetime import datetime, timedelta" >> detect_updates.py
          echo "import os" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "def parse_github_time(time_str):" >> detect_updates.py
          echo "    if not time_str:" >> detect_updates.py
          echo "        return None" >> detect_updates.py
          echo "    try:" >> detect_updates.py
          echo "        return datetime.fromisoformat(time_str.replace('Z', '+00:00'))" >> detect_updates.py
          echo "    except (ValueError, TypeError):" >> detect_updates.py
          echo "        return None" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "current_items = []" >> detect_updates.py
          echo "if os.path.exists('latest_results.json'):" >> detect_updates.py
          echo "    with open('latest_results.json', 'r') as f:" >> detect_updates.py
          echo "        for line in f:" >> detect_updates.py
          echo "            if line.strip():" >> detect_updates.py
          echo "                try:" >> detect_updates.py
          echo "                    current_items.append(json.loads(line))" >> detect_updates.py
          echo "                except json.JSONDecodeError:" >> detect_updates.py
          echo "                    pass" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "previous_items = []" >> detect_updates.py
          echo "if os.path.exists('previous_results_backup.json'):" >> detect_updates.py
          echo "    with open('previous_results_backup.json', 'r') as f:" >> detect_updates.py
          echo "        for line in f:" >> detect_updates.py
          echo "            if line.strip():" >> detect_updates.py
          echo "                try:" >> detect_updates.py
          echo "                    previous_items.append(json.loads(line))" >> detect_updates.py
          echo "                except json.JSONDecodeError:" >> detect_updates.py
          echo "                    pass" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "previous_map = {item['html_url']: item for item in previous_items if 'html_url' in item}" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "updated_urls = []" >> detect_updates.py
          echo "for current in current_items:" >> detect_updates.py
          echo "    url = current.get('html_url')" >> detect_updates.py
          echo "    if not url or url not in previous_map:" >> detect_updates.py
          echo "        continue" >> detect_updates.py
          echo "    " >> detect_updates.py
          echo "    previous = previous_map[url]" >> detect_updates.py
          echo "    " >> detect_updates.py
          echo "    current_updated = parse_github_time(current.get('updated_at'))" >> detect_updates.py
          echo "    previous_updated = parse_github_time(previous.get('updated_at'))" >> detect_updates.py
          echo "    " >> detect_updates.py
          echo "    if not current_updated or not previous_updated:" >> detect_updates.py
          echo "        continue" >> detect_updates.py
          echo "    " >> detect_updates.py
          echo "    time_diff = current_updated - previous_updated" >> detect_updates.py
          echo "    if time_diff > timedelta(hours=1):" >> detect_updates.py
          echo "        star_increase = current.get('stargazers_count', 0) - previous.get('stargazers_count', 0)" >> detect_updates.py
          echo "        current_topics = set(current.get('topics', []))" >> detect_updates.py
          echo "        previous_topics = set(previous.get('topics', []))" >> detect_updates.py
          echo "        new_topics = current_topics - previous_topics" >> detect_updates.py
          echo "        " >> detect_updates.py
          echo "        if time_diff.days < 7 or star_increase > 2 or new_topics:" >> detect_updates.py
          echo "            updated_urls.append(url)" >> detect_updates.py
          echo "            print(f'æ£€æµ‹åˆ°æ›´æ–°: {url}')" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "with open('updated_items.txt', 'w') as f:" >> detect_updates.py
          echo "    for url in updated_urls:" >> detect_updates.py
          echo "        f.write(f'{url}\\n')" >> detect_updates.py
          echo "" >> detect_updates.py
          echo "print(f'å‘ç° {len(updated_urls)} ä¸ªé¡¹ç›®æœ‰æ›´æ–°')" >> detect_updates.py

          python3 detect_updates.py
          UPDATED_COUNT=$(wc -l < updated_items.txt | tr -d ' ')
          
          echo "NEW_COUNT=$NEW_COUNT" >> $GITHUB_ENV
          echo "UPDATED_COUNT=$UPDATED_COUNT" >> $GITHUB_ENV
          echo "CHANGE_COUNT=$((NEW_COUNT + UPDATED_COUNT))" >> $GITHUB_ENV
          
          if [ "$NEW_COUNT" -gt 0 ] || [ "$UPDATED_COUNT" -gt 0 ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate RSS items
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          CURRENT_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          RSS_ITEM_FILE="rss_items.xml"
          
          # åˆ›å»ºæœ‰æ•ˆçš„XMLç»“æ„
          echo '<?xml version="1.0" encoding="UTF-8"?>' > $RSS_ITEM_FILE
          echo '<items>' >> $RSS_ITEM_FILE
          
          # HTMLè½¬ä¹‰å‡½æ•°
          html_escape() {
            echo "$1" | sed 's/&/\&amp;/g; s/</\&lt;/g; s/>/\&gt;/g; s/"/\&quot;/g; s/'"'"'/\&#39;/g'
          }
          
          # å¤„ç†æ–°é¡¹ç›®
          if [ -s new_items.txt ]; then
            echo "å¤„ç† $NEW_COUNT ä¸ªæ–°é¡¹ç›®..."
            while read -r url; do
              # ä»JSONæ–‡ä»¶ä¸­æå–é¡¹ç›®ä¿¡æ¯
              project_info=$(grep -F "\"html_url\":\"$url\"" latest_results.json || grep -F "\"html_url\": \"$url\"" latest_results.json || true)
              if [ -n "$project_info" ]; then
                full_name=$(echo "$project_info" | jq -r '.full_name')
                description=$(echo "$project_info" | jq -r '.description // "No description"')
                description_escaped=$(html_escape "$description")
                
                echo '  <item>' >> $RSS_ITEM_FILE
                echo "    <title>ğŸš€ æ–°é¡¹ç›®: $full_name</title>" >> $RSS_ITEM_FILE
                echo "    <link>$url</link>" >> $RSS_ITEM_FILE
                echo "    <description>æ–°å‘ç°çš„BYOVD/EDRå¯¹æŠ—é¡¹ç›®ã€‚æè¿°: $description_escaped</description>" >> $RSS_ITEM_FILE
                echo "    <pubDate>$CURRENT_DATE</pubDate>" >> $RSS_ITEM_FILE
                echo "    <guid isPermaLink=\"true\">${url}?new=1&amp;ts=$(date +%s)</guid>" >> $RSS_ITEM_FILE
                echo '  </item>' >> $RSS_ITEM_FILE
              fi
            done < new_items.txt
          fi
          
          # å¤„ç†æ›´æ–°é¡¹ç›®
          if [ -s updated_items.txt ]; then
            echo "å¤„ç† $UPDATED_COUNT ä¸ªæ›´æ–°é¡¹ç›®..."
            while read -r url; do
              project_info=$(grep -F "\"html_url\":\"$url\"" latest_results.json || grep -F "\"html_url\": \"$url\"" latest_results.json || true)
              if [ -n "$project_info" ]; then
                full_name=$(echo "$project_info" | jq -r '.full_name')
                description=$(echo "$project_info" | jq -r '.description // "No description"')
                description_escaped=$(html_escape "$description")
                
                echo '  <item>' >> $RSS_ITEM_FILE
                echo "    <title>ğŸ“¢ æ›´æ–°: $full_name</title>" >> $RSS_ITEM_FILE
                echo "    <link>$url</link>" >> $RSS_ITEM_FILE
                echo "    <description>é¡¹ç›®æœ‰é‡è¦æ›´æ–°ï¼Œå¯èƒ½å‘å¸ƒäº†æ–°ç‰ˆæœ¬æˆ–æ·»åŠ äº†æ–°åŠŸèƒ½ã€‚æè¿°: $description_escaped</description>" >> $RSS_ITEM_FILE
                echo "    <pubDate>$CURRENT_DATE</pubDate>" >> $RSS_ITEM_FILE
                echo "    <guid isPermaLink=\"true\">${url}?updated=1&amp;ts=$(date +%s)</guid>" >> $RSS_ITEM_FILE
                echo '  </item>' >> $RSS_ITEM_FILE
              fi
            done < updated_items.txt
          fi
          
          echo '</items>' >> $RSS_ITEM_FILE
          echo "âœ… RSSé¡¹ç›®æ–‡ä»¶ç”Ÿæˆå®Œæˆ"

      - name: Update RSS feed
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          # åˆ›å»ºæ›´æ–°RSS feedçš„Pythonè„šæœ¬
          echo "import xml.etree.ElementTree as ET" > update_rss_feed.py
          echo "from xml.dom import minidom" >> update_rss_feed.py
          echo "from datetime import datetime" >> update_rss_feed.py
          echo "import os" >> update_rss_feed.py
          echo "import re" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "def ensure_rss_structure():" >> update_rss_feed.py
          echo "    rss_file = 'feed.xml'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    if os.path.exists(rss_file):" >> update_rss_feed.py
          echo "        try:" >> update_rss_feed.py
          echo "            tree = ET.parse(rss_file)" >> update_rss_feed.py
          echo "            root = tree.getroot()" >> update_rss_feed.py
          echo "            channel = root.find('channel')" >> update_rss_feed.py
          echo "            if channel is not None:" >> update_rss_feed.py
          echo "                return root, channel" >> update_rss_feed.py
          echo "        except:" >> update_rss_feed.py
          echo "            pass" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    root = ET.Element('rss')" >> update_rss_feed.py
          echo "    root.set('version', '2.0')" >> update_rss_feed.py
          echo "    channel = ET.SubElement(root, 'channel')" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    title = ET.SubElement(channel, 'title')" >> update_rss_feed.py
          echo "    title.text = 'GitHub Monitor: BYOVD & EDR Evasion'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    link = ET.SubElement(channel, 'link')" >> update_rss_feed.py
          echo "    link.text = 'https://github.com/${{ github.repository }}'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    description = ET.SubElement(channel, 'description')" >> update_rss_feed.py
          echo "    description.text = 'ç›‘æ§BYOVDåŠEDRå¯¹æŠ—é¡¹ç›®çš„æ›´æ–°å’Œæ–°å‡ºç°'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    language = ET.SubElement(channel, 'language')" >> update_rss_feed.py
          echo "    language.text = 'en-us'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    return root, channel" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "def parse_rss_items():" >> update_rss_feed.py
          echo "    items = []" >> update_rss_feed.py
          echo "    rss_item_file = 'rss_items.xml'" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    if not os.path.exists(rss_item_file):" >> update_rss_feed.py
          echo "        return items" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    try:" >> update_rss_feed.py
          echo "        with open(rss_item_file, 'r', encoding='utf-8') as f:" >> update_rss_feed.py
          echo "            content = f.read()" >> update_rss_feed.py
          echo "        " >> update_rss_feed.py
          echo "        item_matches = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)" >> update_rss_feed.py
          echo "        for match in item_matches:" >> update_rss_feed.py
          echo "            items.append('<item>' + match + '</item>')" >> update_rss_feed.py
          echo "        " >> update_rss_feed.py
          echo "    except Exception as e:" >> update_rss_feed.py
          echo "        print(f'è§£æRSSé¡¹ç›®æ—¶å‡ºé”™: {e}')" >> update_rss_feed.py
          echo "    " >> update_rss_feed.py
          echo "    return items" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "root, channel = ensure_rss_structure()" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "last_build_date = channel.find('lastBuildDate')" >> update_rss_feed.py
          echo "if last_build_date is not None:" >> update_rss_feed.py
          echo "    channel.remove(last_build_date)" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "rss_items = parse_rss_items()" >> update_rss_feed.py
          echo "for item_xml in reversed(rss_items):" >> update_rss_feed.py
          echo "    try:" >> update_rss_feed.py
          echo "        item_element = ET.fromstring(item_xml)" >> update_rss_feed.py
          echo "        channel.insert(0, item_element)" >> update_rss_feed.py
          echo "    except ET.ParseError as e:" >> update_rss_feed.py
          echo "        print(f'æ— æ³•è§£æitem: {e}')" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "new_last_build_date = ET.SubElement(channel, 'lastBuildDate')" >> update_rss_feed.py
          echo "new_last_build_date.text = datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "rough_string = ET.tostring(root, encoding='unicode')" >> update_rss_feed.py
          echo "parsed = minidom.parseString(rough_string)" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "with open('feed.xml', 'w', encoding='utf-8') as f:" >> update_rss_feed.py
          echo "    f.write(parsed.toprettyxml(indent='  '))" >> update_rss_feed.py
          echo "" >> update_rss_feed.py
          echo "print('RSS feedæ›´æ–°å®Œæˆ')" >> update_rss_feed.py
          
          python3 update_rss_feed.py
          grep -v '^[[:space:]]*$' feed.xml > feed_temp.xml && mv feed_temp.xml feed.xml
          
      - name: Persist state and commit changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          # ä¿å­˜çŠ¶æ€
          cp latest_results.json previous_results.json
          cp current_urls.txt previous_urls.txt
          
          # é…ç½®Git
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          # æäº¤æ›´æ”¹
          git add feed.xml previous_results.json previous_urls.txt
          git commit -m "CI: Found ${{ env.CHANGE_COUNT }} changes (${{ env.NEW_COUNT }} new, ${{ env.UPDATED_COUNT }} updated)"
          git push

      - name: No changes - update log
        if: steps.check_changes.outputs.has_changes == 'false'
        run: |
          if [ -f feed.xml ]; then
            grep -v '^[[:space:]]*$' feed.xml > feed_temp.xml && mv feed_temp.xml feed.xml
          else
            :
          fi
          
          echo "$(date +"%Y-%m-%d %H:%M:%S") - No changes detected" >> monitor.log
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add monitor.log
          git commit -m "CI: Monitoring completed, no changes" || echo "No changes to commit"
          git push || echo "Nothing to push"

      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-files
          path: |
            api_response.json
            latest_results.json
            current_urls.txt
            new_items.txt
            updated_items.txt
            rss_items.xml
            detect_updates.py
            update_rss_feed.py
          retention-days: 2
